{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fb_train_gdrivev2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5HABXwJ43eOZsepJT4tKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajj8866/facebook_mkt/blob/main/fb_train_gdrivev2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYaDUsJATLoU",
        "outputId": "6375e088-bd0b-497d-eccd-35276a2f466c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Current working directory after mounting:  /content\n",
            "Home directory after mounting:  /root\n",
            "Absolute path to facebook_mkt directory:  /content/drive/MyDrive/facebook_mkt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files, drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "drive.mount('/content/drive/') #Mounting drive folder to contain the folder facebook_mkt\n",
        "print('Current working directory after mounting: ',os.getcwd())\n",
        "print('Home directory after mounting: ', Path.home())\n",
        "os.chdir(Path(Path.cwd(), 'drive','MyDrive', 'facebook_mkt'))\n",
        "print('Absolute path to facebook_mkt directory: ', os.path.abspath(Path.cwd()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp 'images.zip'\n",
        "!unzip -q images.zip\n",
        "!rm images.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtAv-mBATxSF",
        "outputId": "b4f1a36d-4cfd-4b29-d00c-17914ccbf744"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: missing destination file operand after 'images.zip'\n",
            "Try 'cp --help' for more information.\n",
            "replace __MACOSX/._images? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchbearer\n",
        "!pip install XlsxWriter\n",
        "print(os.getcwd())\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWAiKLR-TxZx",
        "outputId": "947e2c7b-f768-46f7-fcf1-fdd208269490"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchbearer\n",
            "  Downloading torchbearer-0.5.3-py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchbearer) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from torchbearer) (1.11.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchbearer) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->torchbearer) (4.2.0)\n",
            "Installing collected packages: torchbearer\n",
            "Successfully installed torchbearer-0.5.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting XlsxWriter\n",
            "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 29.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: XlsxWriter\n",
            "Successfully installed XlsxWriter-3.0.3\n",
            "/content/drive/MyDrive/facebook_mkt\n",
            "['torch_fb_run.ipynb', 'data_files', '__MACOSX', 'runs', 'images']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir='/content/drive/MyDrive/facebook_mkt/runs'\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from itertools import product\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import json \n",
        "import torchvision.transforms as transforms\n",
        "import re\n",
        "from PIL import Image\n",
        "import multiprocessing\n",
        "import torchvision\n",
        "from skimage import io\n",
        "from skimage import img_as_float\n",
        "from skimage.filters import sobel\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchbearer import Trial\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision.transforms import Normalize, ToPILImage, ToTensor\n",
        "from torchbearer.callbacks import TensorBoard\n",
        "from torch.nn import Module\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from pathlib import Path\n",
        "from torchvision import models, datasets\n",
        "import copy\n",
        "import time\n",
        "from tensorboard import notebook\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "class CleanData:\n",
        "    def __init__(self, tab_names = ['Products']) -> None:\n",
        "        self.tab_names = tab_names\n",
        "        maj_unique_cats = ['Home & Garden ', 'Baby & Kids Stuff ', 'DIY Tools & Materials ', 'Music, Films, Books & Games ', 'Phones, Mobile Phones & Telecoms ', 'Clothes, Footwear & Accessories ', 'Other Goods ', 'Health & Beauty ', 'Sports, Leisure & Travel ', 'Appliances ', 'Computers & Software ','Office Furniture & Equipment ', 'Video Games & Consoles ']\n",
        "        self.major_map_decoder = dict(enumerate(maj_unique_cats))\n",
        "        self.major_map_encoder = {val: key for key, val in self.major_map_decoder.items()}\n",
        "        if 'data_files' not in os.listdir():\n",
        "            os.mkdir(Path(Path.cwd(), 'data_files'))\n",
        "        self.table_dict = {}\n",
        "        for table in tab_names:\n",
        "            self.table_dict[table] = pd.read_json(Path(Path.cwd(),'data_files', table+'.json'))\n",
        "            self.table_dict[table].dropna(inplace = True)\n",
        "            if 'price' in self.table_dict[table].columns:\n",
        "                self.table_dict[table]['price'] = self.table_dict[table][self.table_dict[table]['price'] != 'N/A'.strip()]['price']\n",
        "                self.table_dict[table]['price'] = self.table_dict[table]['price'].str.replace(',', '').str.strip('£').str.strip(' ').astype(np.float32)\n",
        "                self.table_dict[table] = self.table_dict[table][np.round(self.table_dict[table]['price']) != 0]\n",
        "            if 'category' in self.table_dict[table].columns:\n",
        "                self.expand_category(df=table)\n",
        "\n",
        "    \n",
        "    def try_merge(self, df_list):\n",
        "        '''\n",
        "        Combines dataframes passed in into a single dataframe\n",
        "\n",
        "        Parameters:\n",
        "        df_list: Must contain dataframes within self.table_dict passed in as a list\n",
        "        '''\n",
        "        if isinstance(self.tab_names, str):\n",
        "            print('Method not valid when class instantiated with tab_names as type string')\n",
        "        else:\n",
        "            self.new_df = pd.DataFrame(columns = self.table_dict[df_list[0]].columns)\n",
        "            for i in df_list:\n",
        "                self.new_df = pd.concat([self.new_df, self.table_dict[i]], axis=0)\n",
        "        self.table_dict['combined'] = self.new_df\n",
        "        self.table_dict['combined'].dropna(inplace=True)\n",
        "        return self.table_dict['combined']\n",
        "    \n",
        "    def get_na_vals(self, df):\n",
        "        print(f'The following NA values exist if dataframe {df}')\n",
        "        return self.table_dict[df][self.table_dict[df].isna().any(axis=1)]\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        if isinstance(self.tab_names, str):\n",
        "            print(self.df.columns)\n",
        "            print('\\nTable Name: ', self.tab_names, 'With columns:')\n",
        "            return ' | '.join(self.df.columns)\n",
        "        else:\n",
        "            print('\\n')\n",
        "            print('Total of ', f'{len(self.table_dict)} tables')\n",
        "            return '\\n'.join([f'Table Name: {i}: \\n' f'Columns | {\" | \".join(j.columns)} \\n' for i, j in self.table_dict.items()])\n",
        "\n",
        "    def to_excel(self):\n",
        "        for i, j in self.table_dict.items():\n",
        "            ex_writer = pd.ExcelWriter(f'data_files/{i}.xlsx', engine='xlsxwriter')\n",
        "            with ex_writer as writer:\n",
        "                j.to_excel(writer, sheet_name=i)\n",
        "    \n",
        "    def cat_set(self, df = 'Products',cat_col = 'major_category'):\n",
        "        return self.table_dict[df][cat_col].nunique()\n",
        "    \n",
        "    def expand_category(self, df = 'Products'):\n",
        "        self.major_encoder = LabelEncoder()\n",
        "        self.minor_encoder = LabelEncoder()\n",
        "        self.table_dict[df]['major_category'] = self.table_dict[df]['category'].str.split('/').apply(lambda i: i[0])\n",
        "        self.table_dict[df]['minor_category'] = self.table_dict[df]['category'].str.split('/').apply(lambda i: i[1])\n",
        "        self.table_dict[df] = self.table_dict[df][self.table_dict[df]['major_category'] != 'N'.strip()]\n",
        "        self.table_dict[df]['major_category_encoded'] = self.table_dict[df]['major_category'].map(self.major_map_encoder)\n",
        "        self.table_dict[df]['minor_category_encoded'] = self.minor_encoder.fit_transform(self.table_dict[df]['minor_category'])\n",
        "        return self.table_dict[df]\n",
        "    \n",
        "    def inverse_transform(self, input_array, major_minor = 'minor'):\n",
        "        category_dict = {'major': self.major_encoder, 'minor': self.minor_encoder}\n",
        "        try:\n",
        "            return category_dict[major_minor].inverse_transform(input_array)\n",
        "        except TypeError:\n",
        "            return category_dict[major_minor].inverse_transform(input_array.numpy())\n",
        "    \n",
        "    \n",
        "    def sum_by_cat(self, df= 'Products', quant = 0.95):\n",
        "        data = self.expand_category(df)\n",
        "        major = data.groupby('major_category')['price'].describe()\n",
        "        print('Price Statistics Grouped by Major Category')\n",
        "        print(major)\n",
        "        major_cat_list = major.index.tolist()\n",
        "        #sns.boxplot(data=data, x = 'major_category', y = 'price')\n",
        "        products_df = data.loc[:, ['major_category', 'minor_category', 'price']]\n",
        "        for i in major_cat_list:\n",
        "            prod_plot = products_df.loc[products_df['major_category'] == i]\n",
        "            # print(prod_plot['price'].quantile([quant]))\n",
        "            # print(type(prod_plot['price'].quantile([quant][0])))\n",
        "            # print('Number of observations with price more than the 99th quantile: ', len(prod_plot[prod_plot['price'] > prod_plot['price'].quantile([quant][0])]))\n",
        "            # sns.boxplot(data=prod_plot, x='major_category', y='price')\n",
        "            # plt.show()\n",
        "            sns.boxplot(data=prod_plot[prod_plot['price']<prod_plot['price'].quantile([quant][0])], x = 'major_category', y = 'price')\n",
        "            plt.show()\n",
        "\n",
        "    def trim_data(self, df= 'Products', quant = 0.95):\n",
        "        self.table_dict[df] = self.table_dict[df][self.table_dict[df]['price'] > self.table_dict[df]['price'].quantile([quant])]\n",
        "        return self.table_dict[df]\n",
        "\n",
        "    @classmethod\n",
        "    def allTables(cls):\n",
        "        json_list = []\n",
        "        json_regex = re.compile(r'(.*).json$')\n",
        "        for i in os.listdir(Path(Path.cwd(), 'data_files')):\n",
        "            if re.search(json_regex, i) is not None:\n",
        "                json_list.append(re.search(json_regex, i).group(1))\n",
        "        print(json_list)\n",
        "        return cls(tab_names = json_list)\n",
        "\n",
        "#############################################################################################\n",
        "\n",
        "class CleanImages(CleanData):\n",
        "    def __init__(self, tab_names=['Images']) -> None:\n",
        "        super().__init__(tab_names)\n",
        "        self.df = self.table_dict[tab_names[0]].copy()\n",
        "        self.csv_df = None\n",
        "\n",
        "    def img_clean_pil(self, size = 512, mode = 'RGB'):\n",
        "        image_re = re.compile(r'(.*)\\.jpg')\n",
        "        os.chdir('/content/drive/MyDrive/facebook_mkt/images') #\n",
        "        # os.chdir(Path(Path.cwd(), 'images'))\n",
        "        t = 0\n",
        "        for i in os.listdir():\n",
        "            if re.findall(image_re, i) != []:\n",
        "                try:\n",
        "                    temp_image = Image.open(i)\n",
        "                    black_back = Image.new(size=(size, size), mode=temp_image.mode) #, mode=mode\n",
        "                    curr_size = temp_image.size\n",
        "                    max_dim = max(temp_image.size)\n",
        "                    scale_fact = size / max_dim\n",
        "                    resized_image_dim = (int(scale_fact*curr_size[0]), int(scale_fact*curr_size[1]))\n",
        "                    updated_image = temp_image.resize(resized_image_dim)\n",
        "                    black_back.paste(updated_image, ((size- resized_image_dim[0])//2, (size- resized_image_dim[1])//2))\n",
        "                    black_back = black_back.convert(mode)\n",
        "                    t += 1\n",
        "                    black_back.save(i)\n",
        "                except Exception:\n",
        "                    print(i)\n",
        "                    with open('invalid_file.json', 'w') as wrong_form:\n",
        "                        json.dump(i, wrong_form)\n",
        "                    os.remove(i)\n",
        "                    pass\n",
        "        print(t)\n",
        "        os.chdir('/content/drive/MyDrive/facebook_mkt')\n",
        "\n",
        "    def img_clean_sk(self, normalize = False):\n",
        "        image_re = re.compile(r'(.*)\\.jpg')\n",
        "        img = []\n",
        "        img_dim_list = []\n",
        "        img_id = []\n",
        "        image_array = []\n",
        "        img_channels = []\n",
        "        img_num_features = []\n",
        "        img_mode = []\n",
        "        os.chdir(Path(Path.cwd(), 'images'))\n",
        "        for im in os.listdir():\n",
        "            if re.findall(image_re, im) != []:\n",
        "                img.append(im)\n",
        "                image = io.imread(im)\n",
        "                if normalize == True:\n",
        "                    image = img_as_float(image)\n",
        "                img_id.append(re.search(image_re, im).group(1))\n",
        "                image_array.append(image)\n",
        "                img_dim_list.append(image.shape)\n",
        "                if len(image.shape) == 3:\n",
        "                    img_num_features.append(image.shape[2])\n",
        "                else:\n",
        "                    img_num_features.append(1)\n",
        "                img_channels.append(len(image.shape))\n",
        "                img_mode.append(Image.open(im).mode)\n",
        "        os.chdir(Path(Path.cwd().parents[0]))\n",
        "        self.image_frame = pd.DataFrame(data={'image_id': img_id, 'image': img,'image_array': image_array,'image_shape': img_dim_list, 'mode': img_mode})\n",
        "        return self.image_frame\n",
        "    \n",
        "    def to_excel(self, df):\n",
        "        df.to_excel(Path(Path.cwd(), 'data_files','Cleaned_Images.xlsx'), sheet_name = 'images')\n",
        "\n",
        "    def merge_images(self):\n",
        "        self.df.rename({'id': 'image_id', 'product_id': 'id'}, axis=1, inplace=True)\n",
        "        self.final_df = self.image_frame.merge(self.df, on='image_id', how='inner', validate='one_to_many')\n",
        "        #print(self.final_df.head())\n",
        "        return self.final_df\n",
        "    \n",
        "    def edge_detect(self):\n",
        "        try:\n",
        "            self.image_frame['edge_array'] = self.image_frame['image_array'].copy().apply(lambda i: sobel(rgb2gray(i)))\n",
        "        except: \n",
        "            self.image_frame['edge_array'] = self.image_frame['image_array'].copy().apply(lambda i: sobel(i))\n",
        "        return self.image_frame\n",
        "\n",
        "\n",
        "    def total_clean(self, normalize=False, mode = 'RGB', size = 224):\n",
        "        self.img_clean_pil(mode=mode, size=size)\n",
        "        self.img_clean_sk(normalize=normalize)\n",
        "        self.edge_detect()\n",
        "        self.merge_images()\n",
        "        return self.final_df\n",
        "    \n",
        "    def show_random_images(self, col, size, fig_height= 15, fig_width=10):\n",
        "        grid = GridSpec(nrows = size, ncols = size)\n",
        "        fig = plt.figure(figsize=(fig_height, fig_width))\n",
        "        for i, j in product(range(size), range(size)):\n",
        "            fig.add_subplot(grid[i, j]).imshow(self.final_df[col].iloc[np.random.randint(low=0, high=len(self.final_df)-1)])\n",
        "        plt.show()\n",
        "\n",
        "    def describe_data(self, df):\n",
        "        print('\\n')\n",
        "        print('Data frame columnn information')\n",
        "        print(df.info())\n",
        "        print('\\n')\n",
        "        print('#'*20)\n",
        "        print('Dataframe statistical metrics')\n",
        "        #print(df.describe())\n",
        "        print('#'*20)\n",
        "        print('Array and shape')\n",
        "        print(df['image_shape'].unique())\n",
        "        print(df['image_shape'].value_counts())\n",
        "\n",
        "#############################################################################################\n",
        "\n",
        "class MergedData:\n",
        "    def __init__(self):\n",
        "        img_class = CleanImages()\n",
        "        prod_class = CleanData(tab_names=['Products'])\n",
        "        self.major_map_encoder = prod_class.major_map_encoder\n",
        "        self.major_map_decoder = prod_class.major_map_decoder\n",
        "        self.prod_frame = prod_class.table_dict['Products'].copy()\n",
        "        self.img_df = img_class.total_clean()\n",
        "        self.merged_frame = self.img_df.merge(self.prod_frame, left_on='id', right_on='id')\n",
        "    \n",
        "    def to_pickle(self):\n",
        "        self.merged_frame.to_pickle(Path(Path.cwd(), 'merged_data.pkl'))\n",
        "    \n",
        "    def get_val_counts(self):\n",
        "        return {'products': self.prod_frame, 'images': self.img_df, 'all': self.merged_frame}\n",
        "      \n",
        "#############################################################################################\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, transformer = transforms.Compose([ToTensor()]), X = 'image_array', y = 'major_category_encoded', img_dir = Path(Path.cwd(), 'images'), img_size=224, train_proportion = 0.8, is_test = False):\n",
        "        '''\n",
        "        X: Can be either 'image' if dataset to be instantiated using image object or 'image_array' if dataset to be instantiated using numpy array \n",
        "        y: Can be either 'major_category_encoded' or 'minor_category_encoded'\n",
        "        '''\n",
        "        self.img_inp_type = X\n",
        "        self.transformer = transformer\n",
        "        self.img_dir = img_dir\n",
        "        self.img_size = img_size\n",
        "        merge_class = MergedData()\n",
        "        merged_df = merge_class.merged_frame\n",
        "        filtered_df = merged_df.loc[:, ['image_id', X, re.sub(re.compile('_encoded$'), '', y), y]].copy()\n",
        "        filtered_df.dropna(inplace=True)\n",
        "        print(filtered_df[y].value_counts())\n",
        "        print(filtered_df[re.sub(re.compile('_encoded$'), '', y)].value_counts())\n",
        "        train_end = int(len(filtered_df)*train_proportion)\n",
        "        if is_test == False:\n",
        "            filtered_df = filtered_df.iloc[:train_end]\n",
        "        elif is_test == True:\n",
        "            filtered_df = filtered_df.iloc[train_end:]\n",
        "        else:\n",
        "            pass\n",
        "        self.dataset_size = len(filtered_df)\n",
        "        self.all_data = filtered_df\n",
        "        print('Total observations in remaining dataset: ', len(filtered_df))\n",
        "        self.y = torch.tensor(filtered_df[y].values)\n",
        "        self.X = filtered_df[X].values\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        if self.img_inp_type == 'image':\n",
        "            try:\n",
        "                self.X[idx] =  Image.open(os.path.join(self.img_dir, self.X[idx]))\n",
        "                if self.transformer is not None:\n",
        "                    self.X[idx] = self.transformer(self.X[idx])\n",
        "            except TypeError:\n",
        "                self.X[idx] = self.X[idx]\n",
        "        elif self.img_inp_type == 'image_array':\n",
        "            try:\n",
        "                # self.X[idx] = torch.from_numpy(np.transpose(self.X[idx], (2,1,0)))\n",
        "                if self.transformer is not None:\n",
        "                    self.X[idx] = self.transformer(self.X[idx])\n",
        "            except TypeError:\n",
        "                self.X[idx] = self.X[idx]\n",
        "        else:\n",
        "            self.X[idx] = self.X[idx]        \n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "#############################################################################################\n",
        "\n",
        "pd.set_option('display.max_colwidth', 400)\n",
        "pd.set_option('display.max_columns', 15)\n",
        "pd.set_option('display.max_rows', 40)\n",
        "plt.rc('axes', titlesize=12)\n",
        "\n",
        "res_model = models.resnet50(pretrained=True)\n",
        "for param in res_model.parameters():\n",
        "    param.requires_grad = False\n",
        "res_model.fc = nn.Sequential(nn.Linear(in_features=2048, out_features=512, bias=True), nn.ReLU(inplace=True), nn.Dropout(p=0.2), nn.Linear(in_features=512, out_features=32), nn.Linear(in_features=32, out_features=13))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "res_model.to(device)\n",
        "\n",
        "opt = optim.Adam\n",
        "optimizer =  opt(res_model.parameters(), lr=0.2)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[5, 10, 15, 20, 25, 30], gamma=0.1) \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def get_loader(img = 'image_array',batch_size=35, split_in_dataset = False, train_prop = 0.8):\n",
        "    train_transformer = transforms.Compose([transforms.RandomRotation(40), transforms.RandomHorizontalFlip(p=0.5), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    test_transformer = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    if split_in_dataset == True:\n",
        "        train_dataset = Dataset(transformer=train_transformer, X=img, img_size=224, is_test=False, train_proportion=train_prop)\n",
        "        test_dataset = Dataset(transformer=test_transformer, X=img, img_size=224, is_test=True, train_proportion=train_prop)\n",
        "        train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "        test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
        "        data_loader_dict = {'train': train_loader, 'eval': test_loader}\n",
        "        return train_dataset.dataset_size, test_dataset.dataset_size, data_loader_dict\n",
        "    else:\n",
        "        image_datsets= Dataset(transformer=test_transformer, X = img, img_size=224, is_test=None)\n",
        "        train_end = int(train_prop*image_datsets.dataset_size)\n",
        "        train_dataset, test_dataset = random_split(image_datsets, lengths=[len(image_datsets.all_data.iloc[:train_end]), len(image_datsets.all_data.iloc[train_end:])])\n",
        "        dataset_dict = {'train': train_dataset, 'eval': test_dataset}\n",
        "        data_loader_dict = {i: DataLoader(dataset_dict[i], batch_size=batch_size, shuffle=True) for i in ['train', 'eval']}\n",
        "        return len(image_datsets.all_data.iloc[:train_end]), len(image_datsets.all_data.iloc[train_end:]), data_loader_dict\n",
        "    \n",
        "prod_dum = CleanData()\n",
        "class_dict = prod_dum.major_map_encoder.keys()\n",
        "classes = list(class_dict)\n",
        "class_values = prod_dum.major_map_encoder.values()\n",
        "class_encoder = prod_dum.major_map_encoder\n",
        "\n",
        "\n",
        "'''Tensorboard Function for Showing Images'''\n",
        "def show_image(input_ten_orig):\n",
        "    input_ten = torch.clone(input_ten_orig)\n",
        "    inv_normalize_array = transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255], std=[1/0.229, 1/0.224, 1/0.255])\n",
        "    inv_normalize = transforms.Compose([inv_normalize_array])\n",
        "    input_ten = inv_normalize(input_ten)\n",
        "    input_numpy = input_ten.numpy()\n",
        "    plt.imshow(np.transpose(input_numpy, (1, 2, 0)))\n",
        "    # plt.show()\n",
        "\n",
        "'''Function for comparing actual images to predicted images in Tensorboard'''\n",
        "def images_to_proba(input_arr, model = res_model): #Stub function used in plot_classes_preds to \n",
        "    input_tensor = torch.clone(input_arr)\n",
        "    output = model(input_tensor)\n",
        "    _, predicted_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(predicted_tensor.cpu().numpy())\n",
        "    return preds, [F.softmax(out, dim=0)[pred_val].item() for pred_val, out in zip(preds, output)]\n",
        "\n",
        "def plot_classes_preds(input_arr, lab, model = res_model):\n",
        "    preds, proba = images_to_proba(input_arr, model)\n",
        "    print(preds)\n",
        "    print(proba)\n",
        "    fig = plt.figure(figsize=(12, 12))\n",
        "    for i in range(4):\n",
        "        ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
        "        show_image(input_arr[i])\n",
        "        ax.set_title('{0}, {1:.1f}%\\n(label: {2})'.format(classes[preds[i]], proba[i]*100, classes[lab[i]]), color=('green' if preds[i]==lab[i].item() else 'red')) #\n",
        "        plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "'Model training and testing function'\n",
        "\n",
        "\n",
        "def train_model(model=res_model, optimizer=optimizer, loss_type = criterion, num_epochs = 50, mode_scheduler = scheduler, batch_size = 32, image_type='image_array', split_in_datset=False):\n",
        "    best_model_weights = copy.deepcopy(model.state_dict()) #May be changed at end of each \"for phase block\"\n",
        "    best_accuracy = 0 # May be changed at end of each \"for phase block\"\n",
        "    start = time.time()\n",
        "    writer = SummaryWriter()\n",
        "    train_size, test_size, data_loader_dict = get_loader(batch_size=batch_size, img=image_type, split_in_dataset=split_in_datset)\n",
        "    dataset_size = {'train': train_size, 'eval': test_size}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('\\n')\n",
        "        print('#'*20)\n",
        "        print('Epoch Number: ', epoch)\n",
        "        for phase in ['train', 'eval']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            \n",
        "            running_loss = 0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for batch_num, (inputs, labels) in enumerate(data_loader_dict[phase], start=1):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad() # Gradients reset to zero at beginning of both training and evaluation phase\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # print(inputs)\n",
        "                    # print(inputs.size())\n",
        "                    outputs = model(inputs)\n",
        "                    #outputs = torch.softmax(outputs, dim=1)\n",
        "                    preds = torch.argmax(outputs, dim=1)\n",
        "                    loss = loss_type(outputs, labels)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward() #Calculates gradients\n",
        "                        optimizer.step()\n",
        "\n",
        "                if batch_num%100==0:\n",
        "                    '''Writer functions for batch'''\n",
        "                    #writer.add_figure('Predictions vs Actual',plot_classes_preds(input_arr=inputs, lab=labels, model=model))\n",
        "                    writer.add_scalar(f'Accuracy for phase {phase} by batch number', preds.eq(labels).sum()/batch_size, batch_num)\n",
        "                    writer.add_scalar(f'Average loss for phase {phase} by batch number', loss.item(), batch_num)\n",
        "\n",
        "                running_corrects = running_corrects + preds.eq(labels).sum()\n",
        "                running_loss = running_loss + (loss.item()*inputs.size(0))\n",
        "\n",
        "            if (phase=='train') and (mode_scheduler is not None):\n",
        "                mode_scheduler.step()\n",
        "\n",
        "            '''Writer functions for epoch'''\n",
        "            epoch_loss = running_loss / dataset_size[phase]\n",
        "            print(f'Size of dataset for phase {phase}', dataset_size[phase])\n",
        "            epoch_acc = running_corrects / dataset_size[phase]\n",
        "            writer.add_scalar(f'Accuracy by epoch phase {phase}', epoch_acc, epoch)\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "            writer.add_scalar(f'Average loss by epoch phase {phase}', epoch_loss, epoch)\n",
        "            writer.flush()\n",
        "\n",
        "            if phase == 'eval' and epoch_acc > best_accuracy:\n",
        "                best_accuracy = epoch_acc\n",
        "                best_model_weights = copy.deepcopy(model.state_dict())\n",
        "                print(f'Best val Acc: {best_accuracy:.4f}')\n",
        "\n",
        "\n",
        "    model.load_state_dict(best_model_weights)\n",
        "    torch.save(model.state_dict(), 'image_model.pt')\n",
        "    time_diff = time.time()-start\n",
        "    print(f'Time taken for model to run: {(time_diff//60)} minutes and {(time_diff%60):.0f} seconds')\n",
        "    return model\n",
        "\n",
        "model_tr = train_model()\n",
        "%reload_ext tensorboard\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "BhNSGslsTxmC",
        "outputId": "a5f0dad2-e1ea-47d1-b441-df1b359e507f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir='/content/drive/MyDrive/facebook_mkt/runs'\n"
      ],
      "metadata": {
        "id": "eSp8f_B7dsOi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "outputId": "37b43e29-0c28-437b-8d96-864103002243"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 473), started 0:30:31 ago. (Use '!kill 473' to kill it.)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "keMXpxJvIBS2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}